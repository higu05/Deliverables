```python
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Powered Research Assistant\n",
    "This notebook implements a research assistant that processes PDF documents to generate summaries and citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "!pip install faiss-cpu PyPDF2 openai gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'your-api-key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from dataclasses import dataclass\n",
    "import os\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    OPENAI_API_KEY: str = os.getenv('OPENAI_API_KEY', '')\n",
    "    CHUNK_SIZE: int = 1000\n",
    "    OVERLAP: int = 200\n",
    "    MAX_TOKENS: int = 4000\n",
    "    MODEL_NAME: str = \"gpt-3.5-turbo\"\n",
    "    TEMPERATURE: float = 0.7\n",
    "    EMBEDDING_MODEL: str = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "@dataclass\n",
    "class Document:\n",
    "    content: str\n",
    "    metadata: dict\n",
    "\n",
    "@dataclass\n",
    "class Summary:\n",
    "    text: str\n",
    "    source_doc: str\n",
    "\n",
    "@dataclass\n",
    "class Citation:\n",
    "    text: str\n",
    "    page: int\n",
    "    document: str\n",
    "\n",
    "class DocumentRepository(ABC):\n",
    "    @abstractmethod\n",
    "    async def save(self, document: Document) -> str:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    async def get(self, id: str) -> Document:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "class FaissDocumentStore(DocumentRepository):\n",
    "    def __init__(self):\n",
    "        self.dimension = 1536  # Ada embedding dimension\n",
    "        self.index = faiss.IndexFlatL2(self.dimension)\n",
    "        self.documents = {}\n",
    "        self.doc_counter = 0\n",
    "\n",
    "    async def save(self, document: Document) -> str:\n",
    "        doc_id = str(self.doc_counter)\n",
    "        self.documents[doc_id] = document\n",
    "        self.doc_counter += 1\n",
    "        return doc_id\n",
    "\n",
    "    async def get(self, id: str) -> Document:\n",
    "        return self.documents.get(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import PyPDF2\n",
    "import io\n",
    "\n",
    "class PDFProcessor:\n",
    "    def __init__(self, chunk_size: int = 1000, overlap: int = 200):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.overlap = overlap\n",
    "\n",
    "    def process_pdf(self, pdf_content: bytes) -> List[Document]:\n",
    "        pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_content))\n",
    "        documents = []\n",
    "        \n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text = page.extract_text()\n",
    "            chunks = self._create_chunks(text)\n",
    "            \n",
    "            for chunk in chunks:\n",
    "                doc = Document(\n",
    "                    content=chunk,\n",
    "                    metadata={\"page\": page_num + 1}\n",
    "                )\n",
    "                documents.append(doc)\n",
    "                \n",
    "        return documents\n",
    "\n",
    "    def _create_chunks(self, text: str) -> List[str]:\n",
    "        chunks = []\n",
    "        start = 0\n",
    "        while start < len(text):\n",
    "            end = start + self.chunk_size\n",
    "            chunk = text[start:end]\n",
    "            chunks.append(chunk)\n",
    "            start = end - self.overlap\n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import openai\n",
    "\n",
    "class AIService:\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        openai.api_key = config.OPENAI_API_KEY\n",
    "\n",
    "    async def generate_summary(self, text: str) -> Summary:\n",
    "        response = await openai.ChatCompletion.create(\n",
    "            model=self.config.MODEL_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a research assistant. Summarize the following text.\"},\n",
    "                {\"role\": \"user\", \"content\": text}\n",
    "            ],\n",
    "            temperature=self.config.TEMPERATURE,\n",
    "            max_tokens=self.config.MAX_TOKENS\n",
    "        )\n",
    "        return Summary(\n",
    "            text=response.choices[0].message.content,\n",
    "            source_doc=text[:100] + \"...\"\n",
    "        )\n",
    "\n",
    "    async def generate_citations(self, text: str) -> List[Citation]:\n",
    "        response = await openai.ChatCompletion.create(\n",
    "            model=self.config.MODEL_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Extract key citations from the following text.\"},\n",
    "                {\"role\": \"user\", \"content\": text}\n",
    "            ],\n",
    "            temperature=self.config.TEMPERATURE\n",
    "        )\n",
    "        citations = []\n",
    "        for line in response.choices[0].message.content.split('\\n'):\n",
    "            if line.strip():\n",
    "                citations.append(Citation(\n",
    "                    text=line,\n",
    "                    page=1,\n",
    "                    document=\"source\"\n",
    "                ))\n",
    "        return citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import gradio as gr\n",
    "\n",
    "class ResearchAssistantUI:\n",
    "    def __init__(self):\n",
    "        self.config = Config()\n",
    "        self.pdf_processor = PDFProcessor()\n",
    "        self.ai_service = AIService(self.config)\n",
    "        self.document_store = FaissDocumentStore()\n",
    "\n",
    "    async def process_file(self, file):\n",
    "        if file is None:\n",
    "            return \"Please upload a PDF file.\"\n",
    "        \n",
    "        try:\n",
    "            documents = self.pdf_processor.process_pdf(file)\n",
    "            \n",
    "            for doc in documents:\n",
    "                await self.document_store.save(doc)\n",
    "            \n",
    "            if documents:\n",
    "                summary = await self.ai_service.generate_summary(documents[0].content)\n",
    "                citations = await self.ai_service.generate_citations(documents[0].content)\n",
    "                \n",
    "                result = f\"Summary:\\n{summary.text}\\n\\nKey Citations:\\n\"\n",
    "                for citation in citations:\n",
    "                    result += f\"- {citation.text}\\n\"\n",
    "                \n",
    "                return result\n",
    "            \n",
    "            return \"No content found in PDF.\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error processing file: {str(e)}\"\n",
    "\n",
    "    def launch(self):\n",
    "        interface = gr.Interface(\n",
    "            fn=self.process_file,\n",
    "            inputs=gr.File(label=\"Upload PDF\", type=\"binary\"),\n",
    "            outputs=gr.Textbox(label=\"Results\", lines=10),\n",
    "            title=\"AI Research Assistant\",\n",
    "            description=\"Upload a research paper PDF to get summary and citations.\"\n",
    "        )\n",
    "        interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "app = ResearchAssistantUI()\n",
    "app.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

```

The file name is `research_assistant.ipynb`. Save this notebook and upload it to Google Colab to run.