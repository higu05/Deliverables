# Fine-Tuning Closed-Source Models via APIs in Google Colab

# Configuration
class Config:
    OPENAI_API_KEY = "your_openai_api_key_here"
    FINE_TUNE_MODEL_NAME = "davinci"
    OUTPUT_MODEL_NAME = "fine_tuned_model"
    TRAINING_DATA_FILE = "training_data.jsonl"
    EPOCHS = 4

# Model Interaction
import openai

class Model:
    def __init__(self, config):
        self.api_key = config.OPENAI_API_KEY
        self.model_name = config.FINE_TUNE_MODEL_NAME
        openai.api_key = self.api_key

    def fine_tune(self, training_file):
        response = openai.FineTune.create(
            training_file=training_file,
            model=self.model_name,
            n_epochs=4
        )
        return response

    def retrieve_model(self, fine_tune_id):
        response = openai.FineTune.retrieve(id=fine_tune_id)
        return response

    def generate_response(self, prompt, fine_tuned_model):
        response = openai.Completion.create(
            model=fine_tuned_model,
            prompt=prompt,
            max_tokens=150
        )
        return response

# Data Processing
import json

class DataService:
    def prepare_training_data(self, raw_data):
        processed_data = [
            {"prompt": sample["prompt"], "completion": sample["completion"]}
            for sample in raw_data
        ]
        return processed_data

    def save_training_data(self, data, file_path):
        with open(file_path, "w") as f:
            for entry in data:
                f.write(json.dumps(entry) + "\n")

    def load_training_data(self, file_path):
        with open(file_path, "r") as f:
            return [json.loads(line) for line in f]

# Controller
import time

class Controller:
    def __init__(self, config, model, data_service):
        self.config = config
        self.model = model
        self.data_service = data_service

    def fine_tune_model(self, raw_data):
        print("Preparing training data...")
        training_data = self.data_service.prepare_training_data(raw_data)
        self.data_service.save_training_data(training_data, self.config.TRAINING_DATA_FILE)

        print("Uploading training data to OpenAI...")
        response = self.model.fine_tune(self.config.TRAINING_DATA_FILE)

        fine_tune_id = response["id"]
        print(f"Fine-tuning started with ID: {fine_tune_id}")

        print("Waiting for fine-tuning to complete...")
        while True:
            status = self.model.retrieve_model(fine_tune_id)
            if status["status"] == "succeeded":
                break
            elif status["status"] == "failed":
                print("Fine-tuning failed.")
                return None
            time.sleep(30)

        fine_tuned_model = status["fine_tuned_model"]
        print(f"Fine-tuning complete. Model ID: {fine_tuned_model}")
        return fine_tuned_model

    def generate_response(self, prompt, fine_tuned_model):
        print(f"Generating response for prompt: {prompt}")
        response = self.model.generate_response(prompt, fine_tuned_model)
        print(f"Response: {response['choices'][0]['text']}")

# Main Execution
def main():
    config = Config()
    model = Model(config)
    data_service = DataService()
    controller = Controller(config, model, data_service)

    # Example raw data
    raw_data = [
        {"prompt": "Translate to French: Hello, how are you?", "completion": "Bonjour, comment Ã§a va?"},
        {"prompt": "What is the capital of France?", "completion": "Paris."}
    ]

    # Fine-tuning process
    fine_tuned_model = controller.fine_tune_model(raw_data)
    if fine_tuned_model:
        # Generate response
        test_prompt = "Translate to French: I love programming."
        controller.generate_response(test_prompt, fine_tuned_model)

# Run the main function
if __name__ == "__main__":
    main()
